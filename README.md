# ğŸº BEES Data Engineering â€“ Breweries Pipeline

## ğŸš§ Status do Projeto e Contexto
Este projeto foi idealizado para demonstrar a construÃ§Ã£o de um pipeline completo de dados, utilizando uma arquitetura robusta baseada na medallion architecture (bronze, silver e gold), com toda a esteira de infraestrutura, engenharia de dados, QA, visualizaÃ§Ã£o e arquitetura de soluÃ§Ã£o. O objetivo foi evidenciar conhecimento prÃ¡tico e aprofundado nas seguintes Ã¡reas:

ğŸ›  Infraestrutura em containers Docker com mÃºltiplos serviÃ§os orquestrados;

ğŸ§± Engenharia de dados batch e streaming com Apache Spark e Kafka;

ğŸ“‚ Armazenamento em camadas com formatos otimizados (JSON, Parquet);

ğŸ§ª Boas prÃ¡ticas de qualidade de dados e monitoramento com Prometheus e Grafana;

ğŸ“Š VisualizaÃ§Ã£o e anÃ¡lise exploratÃ³ria com Matplotlib e Pandas;

ğŸ§  Desenho arquitetural escalÃ¡vel, focado em boas prÃ¡ticas de pipelines de produÃ§Ã£o.

No entanto, devido Ã  conciliaÃ§Ã£o com um momento especial e pessoal â€” **meu casamento e lua de mel** â€”, o projeto segue em fase final de desenvolvimento, com o foco atual na resoluÃ§Ã£o de bugs relacionados ao compartilhamento de arquivos entre containers Docker, especificamente nas etapas Silver e Gold do pipeline.

Apesar disso, para garantir a entrega de uma versÃ£o plenamente funcional e demonstrativa, foi desenvolvido um notebook Jupyter chamado **poc_breweries_pipeline.ipynb** e executado no **Google Colab**, que simula todo o pipeline de forma linear, do consumo da API atÃ© a geraÃ§Ã£o de visualizaÃ§Ãµes analÃ­ticas. Este notebook representa fielmente a lÃ³gica e os resultados esperados do pipeline em produÃ§Ã£o.

## ğŸ“‚ Estrutura do Projeto

```
bees_pipeline/
â”œâ”€â”€ camada_bronze/               # Coleta dados brutos da API via Kafka
â”œâ”€â”€ airflow/                    # DAGs e monitoramento customizado
  â”œâ”€â”€ camada_prata/               # Spark Streaming transforma e grava em Delta Lake
  â”œâ”€â”€ camada_ouro/                # Batch para agregados por tipo/localizaÃ§Ã£o
â”œâ”€â”€ prometheus/                 # ConfiguraÃ§Ã£o do Prometheus
â”œâ”€â”€ grafana/                    # Dashboards do Grafana
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o de todos os serviÃ§os
â””â”€â”€ README.md
```

## âš™ï¸ Arquitetura de Dados


ğŸ“¡ API Open Brewery DB
          â”‚
          â–¼
ğŸ›°ï¸ ProduÃ§Ã£o e Envio dos Dados (Kafka Producer)
          â”‚
          â–¼
ğŸ“¥ Kafka Topic `breweries_raw`
          â”‚
          â–¼
ğŸ§± Camada Bronze (Raw Zone - HDFS)
          â”‚
          â–¼
Inicio (Airflow Trigger DAG)
          â”‚
          â–¼
ğŸ§ª TransformaÃ§Ã£o com PySpark
          â”‚
          â–¼
ğŸ¥ˆ Camada Silver (Staging/Curated)
          â”‚
          â–¼
ğŸ§¹ Limpeza + DeduplicaÃ§Ã£o + Enriquecimento
          â”‚
          â–¼
ğŸ… Camada Gold
          â”‚
          â–¼
ğŸ Fim (DAG Success)
          â”‚
          â–¼
ğŸ“ˆ Monitoramento com Prometheus + Logs
          â”‚
          â–¼
ğŸ“Š Dashboard (Grafana)



### ğŸ **Staging Zone: Kafka**
- Utiliza o **Apache Kafka** como zona de entrada (staging) dos dados oriundos da API pÃºblica [Open Brewery DB](https://www.openbrewerydb.org/).
- Os dados sÃ£o coletados de forma incremental paginada e publicados no tÃ³pico `breweries_raw`.

> â±ï¸ Todos os scripts possuem logs com **timestamp** de inÃ­cio e fim das execuÃ§Ãµes, garantindo rastreabilidade e controle de performance.

---

### ğŸ¥‰ **Camada Bronze (Raw Layer)**
- PersistÃªncia de dados crus no HDFS, organizados por data e particionados por carga.
- Sem transformaÃ§Ãµes aplicadas, apenas ingestÃ£o bruta dos dados consumidos via Kafka.
- Essa camada assegura **reprocessamento confiÃ¡vel** e auditoria.

---

### ğŸ¥ˆ **Camada Silver (Curated Layer)**
- AplicaÃ§Ã£o de **limpeza, deduplicaÃ§Ã£o e padronizaÃ§Ã£o** dos dados.
- Uso do Apache Spark estruturado para processar dados da Bronze e gerar a camada tratada.
- Dados sÃ£o organizados por localidade e categoria.

---

### ğŸ¥‡ **Camada Gold (Analytics Layer)**
- GeraÃ§Ã£o de mÃ©tricas agregadas, como quantidade de cervejarias por estado e tipo.
- CriaÃ§Ã£o de **tabelas analÃ­ticas** otimizadas para visualizaÃ§Ãµes.
- A cada execuÃ§Ã£o, os dados gold sÃ£o **reprocessados e atualizados** para anÃ¡lise rÃ¡pida em dashboards.

---


## â–¶ï¸ InstruÃ§Ãµes de Uso

### 1.1. ğŸ“¦ PrÃ©-requisitos

- Docker e Docker Compose instalados na mÃ¡quina

### 1.2. Clonar o repositÃ³rio

```bash
git clone https://github.com/MaltaIgor/bees-breweries-pipeline.git
cd bees-breweries-pipeline
```

### 2. ğŸš€ Subindo a stack completa

No terminal, execute:

```bash
docker-compose up --build
```

### 3. Credenciais de acesso Airflow

Abrir logs do airflow para copiar a senha do UsuÃ¡rio: `admin`.


## ğŸ“ˆ Dashboards e Monitoramento

### ğŸ“Š **Grafana**
- Integrado ao **Prometheus** para exposiÃ§Ã£o de mÃ©tricas personalizadas dos scripts.
- Acompanhamento em tempo real de:
  - Tempo de execuÃ§Ã£o por etapa
  - Status das execuÃ§Ãµes
  - Volume de dados processados

> Acesse o Grafana via `http://localhost:3000`  
> UsuÃ¡rio: `admin` | Senha: `admin`

---

## âœ… Boas PrÃ¡ticas Adotadas

- OrganizaÃ§Ã£o modular do cÃ³digo com separaÃ§Ã£o clara por camada (Kafka Producer, Bronze, Silver, Gold).
- Logs com timestamps em cada etapa.
- Monitoramento completo com Prometheus e Grafana.
- Uso de particionamento no HDFS para escalabilidade.
- ContainerizaÃ§Ã£o total com Docker e Docker Compose.
- Scripts resilientes a falhas e ausÃªncia de dados com reintento automÃ¡tico.

---

## ğŸš€ Foco em Escalabilidade e Atendimento

### ğŸ” Pontos Fortes:
- Arquitetura desacoplada com **componentes independentes** (Kafka, Spark, Airflow, etc.).
- EscalÃ¡vel horizontalmente com uso de containers.
- Suporte a reprocessamento e rastreabilidade em todas as camadas.
- Facilmente adaptÃ¡vel para ambientes de produÃ§Ã£o em nuvem ou clusters Spark.

### âš ï¸ LimitaÃ§Ãµes (devido ao escopo e tempo):
- **Spark rodando em modo local** dentro do container, sem paralelizaÃ§Ã£o distribuÃ­da.
- **HDFS com configuraÃ§Ã£o mÃ­nima**, sem uso de tecnologias como Apache Ozone para armazenamento sofisticado.
- **Falta de camada de autenticaÃ§Ã£o/seguranÃ§a** (por simplicidade e tempo).
- Algumas anÃ¡lises poderiam ser mais ricas com mais tempo para exploraÃ§Ã£o de dados.

---

## ğŸ”„ Alternativas Arquiteturais

### ğŸ§Š Apache Iceberg (em vez de HDFS tradicional)
- **PrÃ³s:** Schema evolution, versionamento, integraÃ§Ã£o com query engines modernas.
- **Contras:** Requer setup mais complexo e engines compatÃ­veis.

### â˜ï¸ Databricks (com Delta Lake)
- **PrÃ³s:** Plataforma gerenciada, integraÃ§Ã£o com notebooks, escalabilidade nativa, Delta Live Tables.
- **Contras:** Custo elevado, dependÃªncia de vendor, menor controle granular.

### â˜ï¸ AWS Glue + S3 + Athena
- **PrÃ³s:** Serverless, billing por query, altamente escalÃ¡vel e integrado ao ecossistema AWS.
- **Contras:** LatÃªncia para consultas mais complexas, lock-in de plataforma.

### â˜ï¸ Azure Data Factory + Data Lake + Synapse
- **PrÃ³s:** Conectividade nativa com produtos Microsoft, integraÃ§Ã£o com Power BI.
- **Contras:** Curva de aprendizado da suÃ­te Azure, limitaÃ§Ãµes de configuraÃ§Ã£o avanÃ§ada.

---

## ğŸ’¼ InstruÃ§Ãµes Extras

### Visualizar mÃ©tricas no Prometheus

Acesse [http://localhost:9090](http://localhost:9090) e use consultas como:

```promql
airflow_dag_run_failed_total
jvm_memory_bytes_used
```

### Dashboard Grafana

* ConfiguraÃ§Ãµes prÃ©-carregadas em `grafana/provisioning`
* Incluem: DAG Failures, Spark Streaming Metrics, Kafka Metrics

---

## ğŸ”§ Testes

IncluÃ­do em etapas futuras:

* `pytest` para funÃ§Ãµes Python
* Testes de DAG e tarefas no Airflow

---

## ğŸ” ConsideraÃ§Ãµes Finais

> Este projeto foi desenvolvido com foco em **atendimento e escalabilidade**, utilizando ferramentas modernas e open source para construir uma arquitetura resiliente, auditÃ¡vel e facilmente expansÃ­vel.

Apesar das limitaÃ§Ãµes de tempo e infraestrutura (como Spark local e ausÃªncia de paralelizaÃ§Ã£o real), a arquitetura foi construÃ­da com fundamentos sÃ³lidos e boas prÃ¡ticas, e Ã© totalmente extensÃ­vel para ambientes de produÃ§Ã£o com upgrades pontuais.

---

## ğŸŒ Autor

**Igor Malta**
[LinkedIn](https://www.linkedin.com/in/igormalta)
Data Engineer | Cloud & BI | Big Data | Real-Time Systems
